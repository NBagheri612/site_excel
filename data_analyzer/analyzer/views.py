import os
import pandas as pd
import numpy as np
from django.shortcuts import render
from django.contrib import messages
from django.conf import settings
from django.http import HttpResponse
from scipy import stats
import warnings
from io import BytesIO
import re
warnings.filterwarnings('ignore')

def home(request):
    """ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø§ Ø·Ø±Ø§Ø­ÛŒ Ù…Ø¯Ø±Ù†"""
    return render(request, 'analyzer/home.html')

def detect_date_columns(df):
    """ØªØ´Ø®ÛŒØµ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®"""
    date_columns = []
    for col in df.columns:
        try:
            pd.to_datetime(df[col], errors='coerce')
            if not pd.to_datetime(df[col], errors='coerce').isna().all():
                date_columns.append(col)
        except:
            continue
    return date_columns

def generate_insights_and_recommendations(analysis_type, analysis_data, df):
    """ØªÙˆÙ„ÛŒØ¯ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ Ùˆ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯"""
    insights = []
    recommendations = []
    
    if analysis_type == "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯ÛŒ":
        total_missing = analysis_data['ØªØ¹Ø¯Ø§Ø¯ Ù…ÙÙ‚ÙˆØ¯ÛŒ'].sum()
        max_missing_col = analysis_data.loc[analysis_data['ØªØ¹Ø¯Ø§Ø¯ Ù…ÙÙ‚ÙˆØ¯ÛŒ'].idxmax()]
        
        insights.append(f"Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹ {total_missing} Ø¯Ø§Ø¯Ù‡ Ù…ÙÙ‚ÙˆØ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯")
        insights.append(f"Ø³ØªÙˆÙ† '{max_missing_col.name}' Ø¨Ø§ {max_missing_col['ØªØ¹Ø¯Ø§Ø¯ Ù…ÙÙ‚ÙˆØ¯ÛŒ']} Ø¯Ø§Ø¯Ù‡ Ù…ÙÙ‚ÙˆØ¯ÛŒ ({max_missing_col['Ø¯Ø±ØµØ¯ Ù…ÙÙ‚ÙˆØ¯ÛŒ']}%) Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù…Ø´Ú©Ù„ Ø±Ø§ Ø¯Ø§Ø±Ø¯")
        
        if max_missing_col['Ø¯Ø±ØµØ¯ Ù…ÙÙ‚ÙˆØ¯ÛŒ'] > 50:
            recommendations.append("âŒ **Ø³ØªÙˆÙ† Ø¨Ø§ Ø¨ÛŒØ´ Ø§Ø² ÛµÛ°Ùª Ø¯Ø§Ø¯Ù‡ Ù…ÙÙ‚ÙˆØ¯ÛŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª Ø­Ø°Ù Ø´ÙˆØ¯**")
            recommendations.append("ğŸ” **Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù„Øª Ù…ÙÙ‚ÙˆØ¯ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª**")
        elif max_missing_col['Ø¯Ø±ØµØ¯ Ù…ÙÙ‚ÙˆØ¯ÛŒ'] > 20:
            recommendations.append("âš¡ **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯**")
            recommendations.append("ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ø­Ø³Ø§Ø³ÛŒØª Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯**")
        else:
            recommendations.append("âœ… **Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø² Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÛŒØ§ Ù…ÛŒØ§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯**")
            recommendations.append("ğŸ”§ **Ø±ÙˆØ´ KNN Imputation Ø¨Ø±Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯**")
    
    elif analysis_type == "Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ":
        numeric_df = df.select_dtypes(include=[np.number])
        for col in numeric_df.columns:
            col_data = numeric_df[col].dropna()
            if len(col_data) > 0:
                cv = (col_data.std() / col_data.mean()) * 100 if col_data.mean() != 0 else 0
                insights.append(f"Ø³ØªÙˆÙ† '{col}': Ø¶Ø±ÛŒØ¨ ØªØºÛŒÛŒØ±Ø§Øª {cv:.1f}%")
                
                if cv > 50:
                    recommendations.append(f"ğŸ“ˆ **Ø³ØªÙˆÙ† '{col}' Ù†ÙˆØ³Ø§Ù† Ø¨Ø§Ù„Ø§ Ø¯Ø§Ø±Ø¯ - Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª**")
                elif cv < 10:
                    recommendations.append(f"ğŸ“‰ **Ø³ØªÙˆÙ† '{col}' Ù¾Ø§ÛŒØ¯Ø§Ø± Ø§Ø³Øª - Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø«Ø§Ø¨Øª Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª**")
    
    elif analysis_type == "ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª":
        high_outlier_cols = []
        for col, row in analysis_data.iterrows():
            if row['Ø¯Ø±ØµØ¯ Ù¾Ø±Øª'] > 10:
                high_outlier_cols.append((col, row['Ø¯Ø±ØµØ¯ Ù¾Ø±Øª']))
        
        if high_outlier_cols:
            insights.append(f"{len(high_outlier_cols)} Ø³ØªÙˆÙ† Ø¨Ø§ Ø¨ÛŒØ´ Ø§Ø² Û±Û°Ùª Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯")
            for col, percent in high_outlier_cols:
                insights.append(f"Ø³ØªÙˆÙ† '{col}': {percent}% Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Øª")
                recommendations.append(f"ğŸ” **Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù„Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ø¯Ø± Ø³ØªÙˆÙ† '{col}' Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª**")
                recommendations.append(f"âš¡ **Ø¨Ø±Ø§ÛŒ Ø³ØªÙˆÙ† '{col}' Ø§Ø² Ø±ÙˆØ´ Winsorization Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯**")
        else:
            insights.append("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ø¯Ø± Ø­Ø¯ Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ÛŒ Ù‡Ø³ØªÙ†Ø¯")
            recommendations.append("âœ… **Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ù‚Ø¯Ø§Ù… Ø®Ø§ØµÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ù†ÛŒØ³Øª**")
    
    elif analysis_type == "Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ":
        strong_correlations = []
        for col1 in analysis_data.columns:
            for col2 in analysis_data.columns:
                if col1 != col2 and abs(analysis_data.loc[col1, col2]) > 0.7:
                    strong_correlations.append((col1, col2, analysis_data.loc[col1, col2]))
        
        if strong_correlations:
            insights.append(f"{len(strong_correlations)} Ø±Ø§Ø¨Ø·Ù‡ Ù‚ÙˆÛŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯")
            for col1, col2, corr in strong_correlations[:3]:  # ÙÙ‚Ø· Û³ Ù…ÙˆØ±Ø¯ Ø§ÙˆÙ„
                insights.append(f"Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ù‚ÙˆÛŒ Ø¨ÛŒÙ† '{col1}' Ùˆ '{col2}': {corr:.3f}")
                recommendations.append(f"ğŸ“Š **Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ '{col1}' Ùˆ '{col2}' Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯**")
                recommendations.append(f"ğŸ”§ **Ø­Ø°Ù ÛŒÚ©ÛŒ Ø§Ø² Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø¨Ø³ØªÙ‡ Ù‚ÙˆÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø§Ø¨Ø¹Ø§Ø¯ Ø¯Ø§Ø¯Ù‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯**")
    
    elif analysis_type == "Ø¢Ø²Ù…ÙˆÙ† Ù†Ø±Ù…Ø§Ù„ÛŒØªÛŒ":
        normal_cols = []
        non_normal_cols = []
        for col, row in analysis_data.iterrows():
            if row.get('Ù†Ø±Ù…Ø§Ù„') == 'Ø¨Ù„Ù‡':
                normal_cols.append(col)
            else:
                non_normal_cols.append(col)
        
        insights.append(f"{len(normal_cols)} Ø³ØªÙˆÙ† Ù†Ø±Ù…Ø§Ù„ØŒ {len(non_normal_cols)} Ø³ØªÙˆÙ† ØºÛŒØ±Ù†Ø±Ù…Ø§Ù„")
        
        if non_normal_cols:
            recommendations.append("ğŸ“ˆ **Ø¨Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ù†Ø±Ù…Ø§Ù„ Ø§Ø² Ø¢Ø²Ù…ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù¾Ø§Ø±Ø§Ù…ØªØ±ÛŒÚ© Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯**")
            recommendations.append("ğŸ”§ **ØªØ¨Ø¯ÛŒÙ„ Ù„Ú¯Ø§Ø±ÛŒØªÙ…ÛŒ ÛŒØ§ Box-Cox Ø¨Ø±Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯**")
        else:
            recommendations.append("âœ… **Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±ÛŒÚ© Ù…Ù†Ø§Ø³Ø¨ Ù‡Ø³ØªÙ†Ø¯**")
    
    elif "ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡" in analysis_type:
        # ØªØ­Ù„ÛŒÙ„ ÙØµÙ„ÛŒ
        insights.append("Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÙØµÙ„ÛŒ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯")
        recommendations.append("ğŸ“… **Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø§ Ø¯Ø±Ù†Ø¸Ø±Ú¯ÛŒØ±ÛŒ ÙØµÙ„ÛŒØª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯**")
        recommendations.append("ğŸ”® **Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ SARIMA ÛŒØ§ Prophet Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯**")
    
    elif "ØªØ­Ù„ÛŒÙ„ Ø³ÙˆØ¯Ø¢ÙˆØ±ÛŒ" in analysis_type:
        max_profit_col = analysis_data.loc[analysis_data['Ù†Ø³Ø¨Øª Ø¨Ù‡ Ú©Ù„'].idxmax()]
        insights.append(f"Ø³ØªÙˆÙ† '{max_profit_col.name}' Ø¨Ø§ {max_profit_col['Ù†Ø³Ø¨Øª Ø¨Ù‡ Ú©Ù„']}% Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø³Ù‡Ù… Ø±Ø§ Ø¯Ø§Ø±Ø¯")
        recommendations.append("ğŸ’° **ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø¨Ù‡Ø¨ÙˆØ¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø³ÙˆØ¯Ø¢ÙˆØ±ÛŒ Ø¨Ø§Ù„Ø§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯**")
        recommendations.append("ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ø³Ø¨Ø¯ Ù…Ø­ØµÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯**")
    
    # Ø§Ú¯Ø± Ø¨ÛŒÙ†Ø´ Ø®Ø§ØµÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯ØŒ Ø¨ÛŒÙ†Ø´ Ø¹Ù…ÙˆÙ…ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†
    if not insights:
        insights.append("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ú©ÛŒÙÛŒØª Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ÛŒ Ø¨Ø±Ø®ÙˆØ±Ø¯Ø§Ø± Ù‡Ø³ØªÙ†Ø¯")
        recommendations.append("ğŸ“ˆ **Ø§Ø¯Ø§Ù…Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯**")
    
    return {
        'insights': list(set(insights)),  # Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ
        'recommendations': list(set(recommendations))
    }

def generate_smart_analysis(df, analysis_type, analysis_data):
    """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø¨ÛŒÙ†Ø´ Ùˆ Ø±Ø§Ù‡Ú©Ø§Ø±"""
    analysis_result = {
        'data': analysis_data,
        'insights': [],
        'recommendations': []
    }
    
    # ØªÙˆÙ„ÛŒØ¯ Ø¨ÛŒÙ†Ø´ Ùˆ Ø±Ø§Ù‡Ú©Ø§Ø±
    smart_analysis = generate_insights_and_recommendations(analysis_type, analysis_data, df)
    analysis_result['insights'] = smart_analysis['insights']
    analysis_result['recommendations'] = smart_analysis['recommendations']
    
    return analysis_result

def generate_basic_analysis(df):
    """ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    analyses = {}
    
    # Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ
    numeric_df = df.select_dtypes(include=[np.number])
    if not numeric_df.empty:
        analyses['Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ'] = generate_smart_analysis(
            df, "Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ", numeric_df.describe().round(2)
        )
    
    # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯ÛŒ
    missing_data = df.isnull().sum()
    missing_percentage = (df.isnull().sum() / len(df) * 100).round(2)
    missing_analysis = pd.DataFrame({
        'ØªØ¹Ø¯Ø§Ø¯ Ù…ÙÙ‚ÙˆØ¯ÛŒ': missing_data,
        'Ø¯Ø±ØµØ¯ Ù…ÙÙ‚ÙˆØ¯ÛŒ': missing_percentage
    })
    analyses['Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯ÛŒ'] = generate_smart_analysis(
        df, "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯ÛŒ", 
        missing_analysis[missing_analysis['ØªØ¹Ø¯Ø§Ø¯ Ù…ÙÙ‚ÙˆØ¯ÛŒ'] > 0]
    )
    
    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ
    info_analysis = pd.DataFrame({
        'ÙˆÛŒÚ˜Ú¯ÛŒ': ['ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙ', 'ØªØ¹Ø¯Ø§Ø¯ Ø³ØªÙˆÙ†', 'ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯ÛŒ', 'ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ', 'ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ'],
        'Ù…Ù‚Ø¯Ø§Ø±': [
            len(df), 
            len(df.columns), 
            df.isnull().sum().sum(), 
            len(numeric_df.columns),
            len(df.select_dtypes(include=['object']).columns)
        ]
    })
    analyses['Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ'] = generate_smart_analysis(df, "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ", info_analysis)
    
    # Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
    if len(numeric_df.columns) > 1:
        correlation_matrix = numeric_df.corr().round(3)
        analyses['Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ'] = generate_smart_analysis(
            df, "Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ", correlation_matrix
        )
    
    return analyses

def generate_time_analysis(df):
    """ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    analyses = {}
    date_columns = detect_date_columns(df)
    
    if date_columns:
        try:
            date_col = date_columns[0]
            df_temp = df.copy()
            df_temp[date_col] = pd.to_datetime(df_temp[date_col])
            df_temp = df_temp.set_index(date_col)
            
            # ØªØ­Ù„ÛŒÙ„ ÙØµÙ„ÛŒ
            df_temp['month'] = df_temp.index.month
            df_temp['quarter'] = df_temp.index.quarter
            df_temp['year'] = df_temp.index.year
            
            numeric_cols = df_temp.select_dtypes(include=[np.number]).columns
            numeric_cols = [col for col in numeric_cols if col not in ['month', 'quarter', 'year']]
            
            if len(numeric_cols) > 0:
                # ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡
                monthly_analysis = df_temp.groupby('month')[numeric_cols].mean().round(2)
                analyses['ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡'] = generate_smart_analysis(
                    df, "ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡", monthly_analysis
                )
                
                # ØªØ­Ù„ÛŒÙ„ ÙØµÙ„ÛŒ
                quarterly_analysis = df_temp.groupby('quarter')[numeric_cols].mean().round(2)
                analyses['ØªØ­Ù„ÛŒÙ„ ÙØµÙ„ÛŒ'] = generate_smart_analysis(
                    df, "ØªØ­Ù„ÛŒÙ„ ÙØµÙ„ÛŒ", quarterly_analysis
                )
                
                # ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ù„Ø§Ù†Ù‡
                yearly_analysis = df_temp.groupby('year')[numeric_cols].mean().round(2)
                analyses['ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ù„Ø§Ù†Ù‡'] = generate_smart_analysis(
                    df, "ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ù„Ø§Ù†Ù‡", yearly_analysis
                )
        
        except Exception as e:
            error_df = pd.DataFrame({'Ø®Ø·Ø§': [f'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø²Ù…Ø§Ù†ÛŒ: {str(e)}']})
            analyses['Ø®Ø·Ø§'] = generate_smart_analysis(df, "Ø®Ø·Ø§", error_df)
    
    return analyses

def generate_statistical_analysis(df):
    """ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    analyses = {}
    numeric_df = df.select_dtypes(include=[np.number])
    
    if not numeric_df.empty:
        # ØªØ­Ù„ÛŒÙ„ Ù†Ø±Ù…Ø§Ù„ÛŒØªÛŒ
        normality_test = {}
        for col in numeric_df.columns:
            try:
                if len(numeric_df[col].dropna()) > 3:
                    stat, p_value = stats.shapiro(numeric_df[col].dropna())
                    normality_test[col] = {
                        'Ø¢Ù…Ø§Ø±Ù‡': round(stat, 4),
                        'p-value': round(p_value, 4),
                        'Ù†Ø±Ù…Ø§Ù„': 'Ø¨Ù„Ù‡' if p_value > 0.05 else 'Ø®ÛŒØ±'
                    }
            except:
                normality_test[col] = {'Ø®Ø·Ø§': 'Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒ'}
        
        analyses['Ø¢Ø²Ù…ÙˆÙ† Ù†Ø±Ù…Ø§Ù„ÛŒØªÛŒ'] = generate_smart_analysis(
            df, "Ø¢Ø²Ù…ÙˆÙ† Ù†Ø±Ù…Ø§Ù„ÛŒØªÛŒ", pd.DataFrame(normality_test).T
        )
        
        # ØªØ­Ù„ÛŒÙ„ Ù¾Ø±Øªâ€ŒÙ‡Ø§
        outliers_analysis = {}
        for col in numeric_df.columns:
            Q1 = numeric_df[col].quantile(0.25)
            Q3 = numeric_df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = ((numeric_df[col] < lower_bound) | (numeric_df[col] > upper_bound)).sum()
            outlier_percentage = (outliers / len(numeric_df[col])) * 100
            
            outliers_analysis[col] = {
                'ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø±Øª': outliers,
                'Ø¯Ø±ØµØ¯ Ù¾Ø±Øª': round(outlier_percentage, 2),
                'Ú©Ø±Ø§Ù† Ù¾Ø§ÛŒÛŒÙ†': round(lower_bound, 2),
                'Ú©Ø±Ø§Ù† Ø¨Ø§Ù„Ø§': round(upper_bound, 2)
            }
        
        analyses['ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª'] = generate_smart_analysis(
            df, "ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª", pd.DataFrame(outliers_analysis).T
        )
    
    return analyses

def generate_business_analysis(df):
    """ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø± Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    analyses = {}
    numeric_df = df.select_dtypes(include=[np.number])
    
    if not numeric_df.empty:
        # ØªØ­Ù„ÛŒÙ„ Ø³ÙˆØ¯Ø¢ÙˆØ±ÛŒ
        profitability = {}
        total_sum = numeric_df.sum().sum()
        for col in numeric_df.columns:
            if numeric_df[col].sum() > 0:
                profitability[col] = {
                    'Ù…Ø¬Ù…ÙˆØ¹': round(numeric_df[col].sum(), 2),
                    'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†': round(numeric_df[col].mean(), 2),
                    'Ù†Ø³Ø¨Øª Ø¨Ù‡ Ú©Ù„': round((numeric_df[col].sum() / total_sum) * 100, 2) if total_sum > 0 else 0
                }
        
        if profitability:
            analyses['ØªØ­Ù„ÛŒÙ„ Ø³ÙˆØ¯Ø¢ÙˆØ±ÛŒ'] = generate_smart_analysis(
                df, "ØªØ­Ù„ÛŒÙ„ Ø³ÙˆØ¯Ø¢ÙˆØ±ÛŒ", pd.DataFrame(profitability).T
            )
        
        # ØªØ­Ù„ÛŒÙ„ Ø±Ø´Ø¯
        growth_analysis = {}
        for col in numeric_df.columns:
            if len(numeric_df[col]) > 1:
                try:
                    first_val = numeric_df[col].iloc[0]
                    last_val = numeric_df[col].iloc[-1]
                    if first_val != 0:
                        growth = ((last_val - first_val) / abs(first_val)) * 100
                        growth_analysis[col] = round(growth, 2)
                except:
                    growth_analysis[col] = 'Ø®Ø·Ø§'
        
        if growth_analysis:
            analyses['Ø¯Ø±ØµØ¯ Ø±Ø´Ø¯ Ú©Ù„ÛŒ'] = generate_smart_analysis(
                df, "Ø¯Ø±ØµØ¯ Ø±Ø´Ø¯ Ú©Ù„ÛŒ", 
                pd.DataFrame.from_dict(growth_analysis, orient='index', columns=['Ø¯Ø±ØµØ¯ Ø±Ø´Ø¯'])
            )
    
    return analyses

def download_analysis_report(request, analysis_type, file_name):
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ ØµÙˆØ±Øª ÙØ§ÛŒÙ„ Excel"""
    try:
        file_path = os.path.join(settings.MEDIA_ROOT, 'results', f'{file_name}_analysis.xlsx')
        
        if not os.path.exists(file_path):
            messages.error(request, 'ÙØ§ÛŒÙ„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯')
            return render(request, 'analyzer/analysis_results.html')
        
        with pd.ExcelFile(file_path) as xls:
            sheet_names = xls.sheet_names
            target_sheet = None
            for sheet in sheet_names:
                if analysis_type in sheet:
                    target_sheet = sheet
                    break
            
            if not target_sheet:
                target_sheet = sheet_names[0] if sheet_names else 'Sheet1'
            
            df = pd.read_excel(xls, sheet_name=target_sheet)
        
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name=analysis_type, index=True)
        
        output.seek(0)
        
        response = HttpResponse(
            output.getvalue(),
            content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
        response['Content-Disposition'] = f'attachment; filename="{file_name}_{analysis_type}.xlsx"'
        
        return response
        
    except Exception as e:
        messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´: {str(e)}')
        return render(request, 'analyzer/analysis_results.html')

def upload_dataset(request):
    """Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„"""
    if request.method == 'POST':
        if 'file' not in request.FILES:
            messages.error(request, 'Ù„Ø·ÙØ§ ÛŒÚ© ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯')
            return render(request, 'analyzer/upload.html')
        
        file = request.FILES['file']
        
        if not file.name.lower().endswith(('.xlsx', '.xls')):
            messages.error(request, 'ÙÙ‚Ø· ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„ Ø¨Ø§ Ù¾Ø³ÙˆÙ†Ø¯ .xlsx Ùˆ .xls Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ Ù‡Ø³ØªÙ†Ø¯')
            return render(request, 'analyzer/upload.html')
        
        try:
            df = pd.read_excel(file)
            results_dir = os.path.join(settings.MEDIA_ROOT, 'results')
            os.makedirs(results_dir, exist_ok=True)
            
            file_name = os.path.splitext(file.name)[0]
            date_columns = detect_date_columns(df)
            
            # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
            all_analyses = {
                'Ù¾Ø§ÛŒÙ‡': generate_basic_analysis(df),
                'Ø²Ù…Ø§Ù†ÛŒ': generate_time_analysis(df),
                'Ø¢Ù…Ø§Ø±ÛŒ': generate_statistical_analysis(df),
                'Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø±': generate_business_analysis(df)
            }
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù‡Ù…Ù‡ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„ Excel
            output_file = os.path.join(results_dir, f'{file_name}_analysis.xlsx')
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                for category, analyses in all_analyses.items():
                    for analysis_name, analysis_data in analyses.items():
                        sheet_name = f"{category}_{analysis_name}"[:31]
                        analysis_data['data'].to_excel(writer, sheet_name=sheet_name, index=True)
                
                df.to_excel(writer, sheet_name='Ø¯Ø§Ø¯Ù‡_Ù‡Ø§ÛŒ_Ø§ØµÙ„ÛŒ', index=False)
            
            # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
            context = {
                'file_name': file_name,
                'output_file': output_file,
                'all_analyses': all_analyses,
                'basic_info': {
                    'rows': len(df),
                    'columns': len(df.columns),
                    'missing_total': df.isnull().sum().sum(),
                    'columns_list': df.columns.tolist(),
                    'has_date_columns': len(date_columns) > 0,
                    'date_columns': date_columns
                }
            }
            
            messages.success(request, f'ÙØ§ÛŒÙ„ "{file_name}" Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªØ­Ù„ÛŒÙ„ Ø´Ø¯!')
            return render(request, 'analyzer/analysis_results.html', context)
            
        except Exception as e:
            messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„: {str(e)}')
            return render(request, 'analyzer/upload.html')
    
    return render(request, 'analyzer/upload.html')

# views.py - Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø±Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ù…Ù†Ø·Ù‚ Ø®ÙˆØ¯ØªØ§Ù† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯
def perform_analysis(request, selected_column):
    """
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø±Ø§ Ú©Ø§Ù…Ù„Ø§ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø®ÙˆØ¯ØªØ§Ù† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯
    """
    # TODO: Ø§ÛŒÙ†Ø¬Ø§ Ø±Ø§ Ø¨Ø§ Ú©Ø¯Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ¯ØªØ§Ù† Ù¾Ø± Ú©Ù†ÛŒØ¯
    # Ù…Ø«Ø§Ù„:
    try:
        filename = request.session.get('excel_filename')
        df = pd.read_excel(f'media/excel_files/{filename}')
        
        # ğŸ”¥ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø±Ø§ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø®ÙˆØ¯ØªØ§Ù† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯
        analysis = {
            'column_name': selected_column,
            'your_custom_analysis': 'Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø´Ù…Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯',
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø´Ù…Ø§
        }
        
        return analysis
        
    except Exception as e:
        return {'error': str(e)}